import os
import sys
import json
import gradio as gr
from datetime import datetime
from typing import List, Dict, Optional
import socket
import time 
import random 

# Install required packages if not available
def install_packages():
    try:
        import google.generativeai as genai
    except ImportError:
        # Simplified installation for execution
        print("üì¶ Installing required packages...")
        os.system(f"{sys.executable} -m pip install -q google-generativeai gradio")
        import google.generativeai as genai
    return genai

genai = install_packages()

# --- Config and Utility Classes ---

class Config:
    GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY", "")
    try:
        from kaggle_secrets import UserSecrets
        user_secrets = UserSecrets()
        if not GEMINI_API_KEY:
            GEMINI_API_KEY = user_secrets.get_secret("GEMINI_API_KEY")
        print("‚úÖ API Key loaded from Kaggle Secrets (if applicable)")
    except ImportError:
        pass

    MODEL_NAME = "gemini-2.5-flash"
    MAX_MEMORY_SIZE = 50 
    AGENT_CHOICES = {
        "Auto (Smart Routing)": None,
        "Resource Curator": "curator",
        "Q&A Specialist": "qa",
        "Career Advisor": "advisor",
        "Resume Specialist": "resume",
        "Interview Coach": "interview"
    }

class Memory:
    """
    Sessions & State Management / Context Engineering
    Stores conversation history and session data (Mood/Timeline).
    """
    def __init__(self, max_size: int = Config.MAX_MEMORY_SIZE):
        self.conversations: List[Dict] = []
        self.max_size = max_size
        self.session_data: Dict = {"mood_log": [], "timeline_data": []}

    def add_interaction(self, role: str, content: str, agent: str = "system"):
        self.conversations.append({
            "timestamp": datetime.now().isoformat(),
            "role": role,
            "content": content,
            "agent": agent
        })
        if len(self.conversations) > self.max_size:
            self.conversations = self.conversations[-self.max_size:]

    def get_context(self, last_n: int = 10) -> str:
        """Context Engineering: Returns the most recent N interactions."""
        recent = self.conversations[-last_n:]
        return "\n".join([f"{msg['role']} ({msg['agent']}): {msg['content']}" for msg in recent])

    def update_session_data(self, key: str, value):
        self.session_data[key] = value

    def get_session_data(self, key: str, default=None):
        return self.session_data.get(key, default)
    
    def log_mood(self, mood: str, intensity: int):
        self.session_data.setdefault("mood_log", []).append({
            "timestamp": datetime.now().isoformat(),
            "mood": mood,
            "intensity": intensity
        })

    def clear(self):
        self.conversations = []
        self.session_data = {"mood_log": [], "timeline_data": []}

class BaseAgent:
    """Base class for all LLM-powered agents."""
    def __init__(self, name: str, role: str, model):
        self.name = name
        self.role = role
        self.model = model

    def process(self, query: str, context: str = "") -> str:
        """Agent powered by an LLM: Core generation logic."""
        raise NotImplementedError

# --- Core LLM-Powered Agents (Parallel Agents) ---

class CuratorAgent(BaseAgent):
    def __init__(self, model): super().__init__("Artheris", "Resource Curator", model)
    def process(self, query: str, context: str = "") -> str:
        prompt = f"""You are a Career Resource Curator. Provide curated resources, articles, courses, and materials. Context: {context}\nQuery: {query}\nProvide structured, actionable resource recommendations with links where possible."""
        try: return self.model.generate_content(prompt).text
        except Exception as e: return f"Error: {str(e)}"

class QAAgent(BaseAgent):
    def __init__(self, model): super().__init__("Artheris", "Q&A Specialist", model)
    def process(self, query: str, context: str = "") -> str:
        prompt = f"""You are a Career Q&A Specialist. Answer career questions accurately with actionable advice. Context: {context}\nQuery: {query}\nProvide a comprehensive, practical answer."""
        try: return self.model.generate_content(prompt).text
        except Exception as e: return f"Error: {str(e)}"

class CareerAdvisorAgent(BaseAgent):
    def __init__(self, model): super().__init__("Artheris", "Career Advisor", model)
    def process(self, query: str, context: str = "") -> str:
        prompt = f"""You are a Professional Career Advisor. Provide personalized guidance, career paths, and development strategies. Context: {context}\nQuery: {query}\nProvide thoughtful, strategic career advice."""
        try: return self.model.generate_content(prompt).text
        except Exception as e: return f"Error: {str(e)}"

class ResumeAgent(BaseAgent):
    def __init__(self, model): super().__init__("Artheris", "Resume Specialist", model)
    def process(self, query: str, context: str = "") -> str:
        prompt = f"""You are a Resume Optimization Specialist. Review resumes, provide improvements, and optimize for ATS. Context: {context}\nQuery: {query}\nProvide specific, actionable resume improvement guidance."""
        try: return self.model.generate_content(prompt).text
        except Exception as e: return f"Error: {str(e)}"

class InterviewAgent(BaseAgent):
    def __init__(self, model): super().__init__("Artheris", "Interview Coach", model)
    def process(self, query: str, context: str = "") -> str:
        prompt = f"""You are an Interview Preparation Coach. Prepare candidates with questions, answers, and strategies. Context: {context}\nQuery: {query}\nProvide practical interview preparation guidance."""
        try: return self.model.generate_content(prompt).text
        except Exception as e: return f"Error: {str(e)}"

# --- NEW FEATURE AGENTS/LOGIC ---

class SandboxAgent(BaseAgent):
    def __init__(self, model):
        super().__init__("Artheris", "Career Simulator", model)

    def process(self, job_title: str) -> str:
        
        prompt = f"""
        **Career Simulation Sandbox - 1 Week in the Life of a {job_title}**
        Act as an unbiased simulator. Detail a typical work week (Monday to Friday) for a person in the '{job_title}' role.
        For each day, describe:
        1. **Key Tasks/Projects:** (e.g., meetings, coding, analysis, client calls).
        2. **Major Decision Point:** Present a realistic dilemma the user must solve.
        3. **Stress Level:** (Low/Medium/High).
        Format the response clearly using Markdown headings for each day.
        End with a summary of the weekly outcomes and a thought-provoking conclusion."""
        try:
            response = self.model.generate_content(prompt).text
            return response
        except Exception as e:
            return f"Error running simulation: {str(e)}"

class ParallelUniverseAgent(BaseAgent):
    def __init__(self, model):
        super().__init__("Artheris", "Parallel Career Generator", model)

    def process(self, current_info: str, context: str) -> str:
        
        prompt = f"""
        **Parallel Universe Career Generator**
        Analyze the user's information and current career context, then hypothesize career paths if they were operating in a dramatically different economy or nation.
        User Context: {current_info}
        Current Conversation Context: {context}
        Suggest **three distinct parallel career trajectories**. For each trajectory, detail:
        1. **Parallel Reality:** (The 'What If...').
        2. **Suggested Role:** (The specific job title).
        3. **Required Adaptation:** (The key skill or mindset change needed).
        Provide creative, insightful, and strategic suggestions."""
        try:
            response = self.model.generate_content(prompt).text
            return response
        except Exception as e:
            return f"Error generating parallel careers: {str(e)}"

# --- Observatory, Orchestrator, and CareerAssistanceSystem ---

class Observatory:
    """Observability: Tracks metrics, logs events, and provides a status report."""
    def __init__(self, logs: List[Dict] = None):
        self.logs: List[Dict] = logs if logs is not None else []
        self.metrics: Dict = {"total_queries": 0, "agent_calls": {}, "errors": 0}
        self.start_time = datetime.now()
        
    def log_event(self, event_type: str, agent: str, details: str):
        self.logs.append({"timestamp": datetime.now().isoformat(), "type": event_type, "agent": agent, "details": details})
        if event_type == "query":
            self.metrics["total_queries"] += 1
            if agent not in self.metrics["agent_calls"]: self.metrics["agent_calls"][agent] = 0
            self.metrics["agent_calls"][agent] += 1
        elif event_type == "error":
            self.metrics["errors"] += 1

    def get_report(self) -> str:
        uptime = datetime.now() - self.start_time
        uptime_str = str(uptime).split('.')[0]
        report = f"""=== System Observatory Report ===\nUptime: {uptime_str}\nTotal Queries: {self.metrics['total_queries']}\nTotal Errors: {self.metrics['errors']}\nAgent Activity:\n"""
        if self.metrics["agent_calls"]:
            for agent, calls in self.metrics["agent_calls"].items(): report += f" - {agent}: {calls} calls\n"
        else: report += " - No calls recorded yet.\n"
        report += f"\nRecent Events (last 5):\n"
        for log in self.logs[-5:]: report += f"[{log['timestamp'].split('T')[1].split('.')[0]}] {log['type']} - {log['agent']}: {log['details']}\n"
        return report

class Orchestrator:
    """Coordinates agents and routes queries in the Multi-Agent System."""
    def __init__(self, agents: Dict[str, BaseAgent], memory: Memory, observatory: Observatory):
        self.agents = agents
        self.memory = memory
        self.observatory = observatory

    def route_query(self, query: str) -> str:
        """Heuristic-based routing to select the best parallel agent."""
        query_lower = query.lower()
        if any(w in query_lower for w in ["resource", "article", "learn", "course", "material", "book"]): return "curator"
        elif any(w in query_lower for w in ["resume", "cv", "curriculum vitae", "optimize my resume"]): return "resume"
        elif any(w in query_lower for w in ["interview", "mock interview", "interview prep", "behavioral question", "tell me about yourself"]): return "interview"
        elif any(w in query_lower for w in ["advice", "guidance", "career path", "transition", "switch", "salary negotiation", "long-term strategy"]): return "advisor"
        else: return "qa"

    def process_query(self, query: str, manual_agent_key: Optional[str] = None) -> str:
        self.observatory.log_event("query", "orchestrator", f"Received: {query[:50]}...")
        
        agent_key = manual_agent_key if manual_agent_key and manual_agent_key in self.agents else self.route_query(query)
        agent = self.agents.get(agent_key)
        if not agent: return "Error: Could not route query to appropriate agent."

        context = self.memory.get_context(last_n=10)
        self.observatory.log_event("routing", "orchestrator", f"Routed to {agent.role}")
        
        response = agent.process(query, context)
        
        self.memory.add_interaction("user", query)
        self.memory.add_interaction("assistant", response, agent.name)
        self.observatory.log_event("response", agent.name, f"Response length: {len(response)} chars")

        return f"**üë§ [{agent.name} - {agent.role}]**\n\n{response}"


class CareerAssistanceSystem:
    """The main system managing the Multi-Agent System, Memory, and Observatory."""
    def __init__(self):
        # API Key is assumed configured globally or handled by Gradio
        self.model = genai.GenerativeModel(Config.MODEL_NAME)
        self.memory = Memory()
        self.observatory = Observatory()
        self.agents = {
            # Core Parallel Agents
            "curator": CuratorAgent(self.model),
            "qa": QAAgent(self.model),
            "advisor": CareerAdvisorAgent(self.model),
            "resume": ResumeAgent(self.model),
            "interview": InterviewAgent(self.model),
            # Feature Agents
            "sandbox": SandboxAgent(self.model), 
            "parallel": ParallelUniverseAgent(self.model)
        }
        self.orchestrator = Orchestrator(self.agents, self.memory, self.observatory)

    def process_message(self, message: str, history: List, manual_agent_key: Optional[str] = None) -> str:
        try:
            return self.orchestrator.process_query(message, manual_agent_key)
        except Exception as e:
            self.observatory.log_event("error", "system", str(e))
            return f"‚ö†Ô∏è Error: {str(e)}"
    
    # --- New Feature Methods ---
    def run_sandbox(self, job_title: str):
        return self.agents["sandbox"].process(job_title)

    def run_parallel(self, user_info: str):
        context = self.memory.get_context(last_n=20)
        return self.agents["parallel"].process(user_info, context)

    def log_mood_and_get_timeline(self, mood: str, intensity: int, timeline_entry: str, timeline_type: str):
        self.memory.log_mood(mood, intensity)
        
        if timeline_entry:
             self.memory.session_data.setdefault("timeline_data", []).append({
                 "timestamp": datetime.now().isoformat(),
                 "type": timeline_type,
                 "entry": timeline_entry
             })
        
        mood_report = self.generate_mood_report()
        timeline_visualization = self.generate_timeline_visualization()
        
        return mood_report, timeline_visualization

    def generate_mood_report(self):
        log = self.memory.get_session_data("mood_log", [])
        if not log:
            return "No mood data logged yet."
        
        latest_mood = log[-1]
        mood_counts = {}
        for entry in log:
            mood_counts[entry['mood']] = mood_counts.get(entry['mood'], 0) + 1
            
        report = f"### üìä Career Mood Tracker Report\n"
        report += f"**Latest Mood:** {latest_mood['mood']} (Intensity: {latest_mood['intensity']}/5) at {latest_mood['timestamp'].split('T')[0]}\n"
        report += f"**Mood Frequency (Total {len(log)} logs):**\n"
        for mood, count in mood_counts.items():
            report += f"- {mood}: {count} times\n"
        
        prompt = f"Analyze the following mood log (Mood: {mood_counts}) and provide a brief, professional interpretation of the user's emotional pattern regarding their career."
        interpretation = self.model.generate_content(prompt).text
        report += f"\n**Professional Interpretation:** {interpretation}"
        return report

    def generate_timeline_visualization(self):
        data = self.memory.get_session_data("timeline_data", [])
        if not data:
            return "No identity timeline data logged yet."

        vis = "### üìú Identity Timeline Builder Data\n"
        for entry in data:
            vis += f"**[{entry['timestamp'].split('T')[0]}]** - **{entry['type']}**:\n > {entry['entry']}\n"
            
        prompt = f"Based on the following life events, interests, and skills ({json.dumps(data)}), generate a single, unified career Identity Statement (3 sentences max)."
        identity_statement = self.model.generate_content(prompt).text
        vis += f"\n**Unified Identity Statement:** {identity_statement}"
        return vis

    def get_system_status(self) -> str:
        return self.observatory.get_report()

    def get_memory_context(self) -> str:
        return self.memory.get_context(last_n=Config.MAX_MEMORY_SIZE)

    def clear_memory(self):
        self.memory.clear()


# --- GRADIO INTERFACE CREATION (MODIFIED) ---

def create_interface(api_key: str):
    
    # Ensure API key is configured before creating the system instance
    genai.configure(api_key=api_key) 
    system = CareerAssistanceSystem()

    def chat_response(message, history, agent_override):
        if not message.strip(): return history
        agent_key = Config.AGENT_CHOICES.get(agent_override)
        yield history + [{"role": "user", "content": message}, {"role": "assistant", "content": "..."}]
        
        response = system.process_message(message, history, agent_key) 
        
        new_history = history + [{"role": "user", "content": message}, {"role": "assistant", "content": response}]
        yield new_history

    def get_status(): return system.get_system_status()
    def get_context(): return system.get_memory_context()
    def clear_chat():
        system.clear_memory()
        return [], system.get_system_status(), gr.update(visible=False)

    def handle_mood_timeline(mood, intensity, timeline_entry, timeline_type):
        return system.log_mood_and_get_timeline(mood, intensity, timeline_entry, timeline_type)
    
    def simulate_sandbox(job_title):
        yield "..."
        response = system.run_sandbox(job_title)
        yield response
        
    def generate_parallel(user_info):
        yield "..."
        response = system.run_parallel(user_info)
        yield response

    # --- ADVANCED, IMMERSIVE CUSTOM CSS STYLING (UPDATED FOR DARK BLUE SUB-HEADING) ---
    custom_css = """
    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@400;600;700;800&family=Poppins:wght@300;400;500;600;700&display=swap');
    
    :root {
        /* Consistent Color Palette */
        --career-primary: #5E35B1; /* Deep Violet (Used for Primary/Buttons) */
        --career-accent: #FF8A65;  /* Coral/Orange Accent (Used for CTA/Logo Border/Glow/Gradient Start) */
        --career-secondary: #4DB6AC; /* Teal/Mint Secondary */
        --career-text-dark: #212121;
        --career-text-light: #ffffff;
        --career-surface: #ffffff;
        --career-background-gradient-start: #ECEFF1;
        --career-background-gradient-end: #CFD8DC;
        --neon-glow: 0 0 8px var(--career-accent), 0 0 20px rgba(255, 138, 101, 0.7);
        --soft-shadow: 0 12px 30px rgba(0, 0, 0, 0.18);
        --border-radius-large: 20px;
        --border-radius-small: 10px;
        --transition-speed: 0.3s;
        
        /* NEW SKY BLUE COLOR FOR MARQUEE */
        --sky-blue: #87CEEB; 
    }

    .gradio-container {
        font-family: 'Poppins', sans-serif;
        background: linear-gradient(135deg, var(--career-background-gradient-start) 0%, var(--career-background-gradient-end) 100%) !important;
        padding: 30px;
    }
    
    /* --- HEADER SECTION (Purple/Teal Gradient Background) --- */
    .header-bar {
        display: flex; align-items: center; gap: 30px; padding: 25px 35px;
        background: linear-gradient(135deg, var(--career-primary) 0%, #7E57C2 50%, var(--career-secondary) 100%);
        color: var(--career-text-light); border-radius: var(--border-radius-large);
        box-shadow: 0 15px 35px rgba(0, 0, 0, 0.4); margin-bottom: 30px;
    }
    
    /* --- LOGO ZOOM-IN ANIMATION STYLES --- */
    .logo-image {
        width: 150px; height: 150px; border-radius: 50%; border: 6px solid var(--career-accent);
        box-shadow: var(--neon-glow); flex-shrink: 0; object-fit: cover;
        
        /* Initial state for animation */
        opacity: 0; 
        transform: scale(0.1);
        
        /* Animation application */
        animation: zoomIn 1.5s cubic-bezier(0.25, 0.46, 0.45, 0.94) forwards;
    }

    @keyframes zoomIn {
        0% {
            transform: scale(0.1); 
            opacity: 0;
        }
        60% {
            transform: scale(1.1); /* Slight overshoot */
            opacity: 1;
        }
        100% {
            transform: scale(1.0);
            opacity: 1;
        }
    }
    
    /* --- MAIN HEADING (H1) STYLES --- */
    .header-bar h1 {
        font-family: 'Montserrat', sans-serif; 
        font-weight: 800; 
        font-size: 3.5em; 
        margin: 0;
        letter-spacing: 1px;
        color: var(--career-text-light); /* Base white text color */
        
        /* Fixed, non-shaking state */
        transform: scale(1);
        text-shadow: 0 0 5px rgba(255,255,255,0.7), 0 0 10px rgba(255,255,255,0.5); 
        
        /* ONLY KEEP glowPulse */
        animation: 
            glowPulse 3s infinite alternate ease-in-out; 
    }

    /* Keyframes for soft glowing pulse (KEPT) */
    @keyframes glowPulse {
        0% {
            text-shadow: 0 0 5px rgba(255,255,255,0.7), 0 0 10px rgba(255,255,255,0.5), 0 0 15px rgba(255,255,255,0.3);
        }
        50% {
            text-shadow: 0 0 10px rgba(255,255,255,1), 0 0 20px rgba(255,255,255,0.8), 0 0 30px rgba(255,255,255,0.6), 0 0 40px rgba(255, 138, 101, 0.4); /* Adding a subtle accent glow */
        }
        100% {
            text-shadow: 0 0 5px rgba(255,255,255,0.7), 0 0 10px rgba(255,255,255,0.5), 0 0 15px rgba(255,255,255,0.3);
        }
    }

    /* --- SUB-HEADING (H3) STYLES (UPDATED TO DARK BLUE) --- */
    .header-bar h3 {
        font-family: 'Poppins', sans-serif; 
        font-weight: 500;
        margin: 5px 0 0 0; 
        font-size: 1.3em; 
        opacity: 1; 
        
        /* Solid Dark Blue Color */
        color: #000080; /* Dark blue color */
        background-image: none; /* Remove gradient */
        -webkit-background-clip: unset; /* Reset background-clip */
        background-clip: unset; /* Reset background-clip */
        
        text-shadow: none; 
    }

    /* --- HORIZONTAL MARQUEE STYLES (SKY BLUE) --- */
    
    .marquee-container {
        width: 100%; 
        overflow: hidden; 
        padding: 10px 0;
        margin-top: 15px; 
        border-radius: var(--border-radius-small);
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
    }
    .marquee-container.horizontal {
        background-color: var(--sky-blue); 
        color: white;
    }

    .animated-text {
        font-size: 1.2em;
        font-weight: 700;
        white-space: nowrap; 
        display: inline-block;
        padding: 0 10px;
    }

    .horizontal-move {
        transform: translateX(100%); 
        animation: move-horizontal 15s linear infinite;
    }

    @keyframes move-horizontal {
        0% {
            transform: translateX(100%); 
        }
        100% {
            transform: translateX(-100%); 
        }
    }

    /* --- GENERAL ALIGNMENT & CARD STYLING --- */
    .gradio-container .panel, .gradio-container .gr-tab {
        background-color: var(--career-surface);
        border-radius: var(--border-radius-large);
        box-shadow: var(--soft-shadow);
        padding: 30px;
        transition: transform var(--transition-speed) ease, box-shadow var(--transition-speed) ease;
        border: none;
    }
    .gradio-container .panel:hover {
        transform: translateY(-4px); 
        box-shadow: 0 18px 45px rgba(0, 0, 0, 0.2);
    }
    
    /* Perfect Alignment for Rows in the Chat Tab */
    .gradio-container .gr-row {
        align-items: flex-end;
    }

    /* --- TAB ENHANCEMENTS --- */
    .gr-tab-button {
        font-weight: 600;
        color: #757575; /* Default inactive color */
        transition: color var(--transition-speed) ease, background-color 0.2s ease;
        padding: 12px 20px !important;
        border-radius: var(--border-radius-small) var(--border-radius-small) 0 0 !important;
    }
    .gr-tab-button:hover {
        background-color: #f0f4f7 !important; /* Light hover background */
        color: var(--career-primary) !important;
    }
    .gr-tab-button.selected {
        color: var(--career-primary) !important;
        background-color: var(--career-surface) !important;
        border-bottom: 3px solid var(--career-primary) !important;
    }
    
    /* --- INPUT & BUTTON CONSISTENCY --- */
    .gr-input, .gr-textbox, .gr-dropdown, .gr-slider {
        border-radius: var(--border-radius-small) !important;
        border: 1px solid #ddd;
        transition: border-color 0.2s, box-shadow 0.2s;
        padding: 10px 15px !important;
    }
    
    /* Input Focus Glow */
    .gr-input:focus-within, 
    .gr-textbox:focus-within, 
    .gr-dropdown.open, 
    .gr-slider-fill { 
        border-color: var(--career-primary) !important;
        box-shadow: 0 0 0 4px rgba(94, 53, 177, 0.25); /* Stronger glow effect */
    }
    
    /* Button Styling */
    .gr-button {
        border-radius: var(--border-radius-small) !important;
        font-weight: 600 !important;
        padding: 12px 20px !important;
        transition: all var(--transition-speed) ease;
    }
    .gr-button.primary {
        background-color: var(--career-primary) !important;
    }
    .gr-button.primary:hover {
        background-color: #512DA8 !important; 
    }
    .gr-button.secondary {
        background-color: #F0F4F7 !important;
        color: var(--career-text-dark) !important;
        border: 1px solid #CFD8DC !important;
    }
    .gr-button.secondary:hover {
        background-color: #E0E5E9 !important;
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
    }

    /* --- CHATBOT MESSAGES --- */
    .message.bot {
        background-color: #F0F4F7 !important; 
        border-top-left-radius: 0 !important;
        padding: 15px; 
    }
    .message.user {
        background-color: var(--career-secondary) !important;
        color: var(--career-text-light) !important;
        border-top-right-radius: 0 !important;
    }

    /* --- CTA BUTTON (Neon Glow & Pulse) --- */
    #cta_button {
        /* Core Style */
        border-radius: 12px; 
        font-size: 1.2em;
        font-weight: 700;
        padding: 18px 35px;
        
        /* 3D/Neon/Reflection */
        background: var(--career-accent);
        color: var(--career-text-light);
        border: 2px solid var(--career-accent);
        text-shadow: 0 0 2px rgba(0, 0, 0, 0.3);
        box-shadow: var(--neon-glow), 0 8px 15px rgba(0, 0, 0, 0.3); 
        position: relative;
        overflow: hidden;
        z-index: 1;
        
        /* Continuous Pulse Animation */
        animation: pulse 2s infinite ease-in-out;
    }
    
    /* Keyframes for the Pulse/Breathing Effect */
    @keyframes pulse {
        0% {
            box-shadow: var(--neon-glow), 0 0 0 0 rgba(255, 138, 101, 0.7);
        }
        50% {
            box-shadow: var(--neon-glow), 0 0 0 15px rgba(255, 138, 101, 0); 
        }
        100% {
            box-shadow: var(--neon-glow), 0 0 0 0 rgba(255, 138, 101, 0.7);
        }
    }
    
    /* Reflection and Hover styles remain the same for depth */
    #cta_button::before {
        content: '';
        position: absolute;
        top: 0; left: 0; width: 100%; height: 100%;
        background: radial-gradient(circle at 10% 20%, rgba(255,255,255,0.4) 0%, rgba(255,255,255,0) 60%);
        opacity: 0.7;
        pointer-events: none;
        z-index: 2;
    }
    
    #cta_button:hover {
        transform: scale(1.02) translateY(-4px); 
        border-color: #ffffff;
        box-shadow: var(--neon-glow), 0 10px 25px rgba(0, 0, 0, 0.5);
    }
    #cta_button:active {
        transform: scale(0.99); 
        box-shadow: inset 0 3px 8px rgba(0, 0, 0, 0.3);
    }
    
    /* --- SCROLLBAR STYLING --- */
    ::-webkit-scrollbar {
        width: 10px;
        height: 10px;
    }
    
    ::-webkit-scrollbar-track {
        background: #f0f4f7; 
        border-radius: 5px;
    }
    
    ::-webkit-scrollbar-thumb {
        background: var(--career-secondary); 
        border-radius: 5px;
    }
    
    ::-webkit-scrollbar-thumb:hover {
        background: #388E81; 
    }
    
    /* --- UI ELEMENTS for Feature Tabs --- */
    
    #timeline_builder_area {
        background-color: #f7f9fb !important;
        border-left: 5px solid var(--career-secondary) !important; 
        padding-left: 20px;
        white-space: pre-wrap;
        border-radius: var(--border-radius-small);
    }
    
    .gr-slider-fill {
        background: linear-gradient(90deg, #FFCDD2 0%, var(--career-accent) 100%) !important;
        border-radius: 50px;
    }
    .gr-slider-thumb {
        background-color: var(--career-primary) !important;
        border: 2px solid var(--career-text-light) !important;
        box-shadow: 0 0 5px rgba(0, 0, 0, 0.3);
    }

    #status_report_box, .agent-info {
        margin-top: 15px;
    }
    
    """
    # ------------------------------------------
    
    with gr.Blocks(theme=gr.themes.Soft(), title="Career Assistance AI", css=custom_css) as demo:

        # --- HEADER SECTION (Logo, Title) ---
        with gr.Row(elem_classes=["header-bar"]):
            gr.Image(value=r"https://img.freepik.com/premium-photo/gradient-hacker-logo-template_1029473-588573.jpg?semt=ais_hybrid&w=740&q=80", label="AI Logo", width=150, height=180, container=False, elem_classes=["logo-image"])
            with gr.Column(elem_classes=["header-text"]):
                # The h1 content is animated via the CSS
                gr.Markdown("<h1>CareerMatrix AI</h1><h3>Multi-Agent Career Assistance System</h3>")

        # --- MAIN INTERFACE TABS ---
        with gr.Tabs(elem_classes=["panel"]):
            
            # 1. Main Chat Assistant
            with gr.TabItem("üí¨ Main Assistant"):
                
                # --- ANIMATED MARQUEE BANNER INTEGRATION ---
                gr.Markdown(
                    '<div class="marquee-container horizontal"><p class="animated-text horizontal-move">‚òÖ CareerMatrix AI is guiding your path to success! ‚òÖ Utilize our specialized agents for optimal advice. ‚òÖ</p></div>',
                    sanitize_html=True 
                )
                
                with gr.Row():
                    with gr.Column(scale=3):
                        chatbot = gr.Chatbot(height=500, label="Artheris - Multi-Agent Chat", show_label=True, avatar_images=(None, "ü§ñ"), type="messages")
                        with gr.Row():
                            agent_selector = gr.Dropdown(label="Specialized Agent Override", choices=list(Config.AGENT_CHOICES.keys()), value="Auto (Smart Routing)", scale=1, interactive=True)
                            msg = gr.Textbox(label="Ask a Question", placeholder="e.g., 'Review my resume' or 'What are the steps for a career transition?'", scale=4, lines=2)
                            submit = gr.Button("üöÄ Send", scale=1, variant="primary")
                        with gr.Row():
                            clear = gr.Button("üóëÔ∏è Clear Conversation & Memory", variant="secondary")
                            view_context_btn = gr.Button("üß† Toggle Memory Context", variant="secondary")
                        with gr.Accordion("üìö Key Agent Commands", open=False):
                             gr.Markdown("- **Resource Curator:** `best resources to learn Python`\n- **Resume Specialist:** `review my CV for an analyst role`\n- **Interview Coach:** `common interview questions for product managers`\n- **Career Advisor:** `advice on transitioning to cybersecurity`\n- **Q&A Specialist:** `What is the salary range for a UX designer?`")

            # 2. Career Simulation Sandbox
            with gr.TabItem("üéÆ Career Simulation Sandbox"):
                with gr.Column():
                    gr.Markdown("## üßë‚Äçüíª Simulate 1 Week on the Job")
                    job_input = gr.Textbox(label="Job Title to Simulate", placeholder="e.g., 'Senior Data Scientist' or 'Startup CTO'", lines=1)
                    simulate_btn = gr.Button("‚ñ∂Ô∏è Run 1-Week Simulation", variant="primary", elem_id="cta_button")
                    simulation_output = gr.Markdown("### Simulation Results\nSimulated tasks, stress level, and key decisions will appear here.")
                
                simulate_btn.click(
                    simulate_sandbox, inputs=[job_input], outputs=[simulation_output]
                )
                job_input.submit(
                    simulate_sandbox, inputs=[job_input], outputs=[simulation_output]
                )

            # 3. Parallel Universe Career Generator (Feature index shifted)
            with gr.TabItem("üåå Parallel Universe"):
                with gr.Column():
                    gr.Markdown("## üëΩ What If? Career Generator")
                    parallel_info = gr.Textbox(label="Your Current Skills/Location", placeholder="e.g., 'Software Engineer in Tokyo with a focus on green tech'", lines=3)
                    parallel_btn = gr.Button("‚ú® Generate Parallel Careers", variant="secondary")
                    parallel_output = gr.Markdown("### Parallel Career Trajectories\nSuggestions based on alternative economic realities will appear here.")
                
                parallel_btn.click(
                    generate_parallel, inputs=[parallel_info], outputs=[parallel_output]
                )
                parallel_info.submit(
                    generate_parallel, inputs=[parallel_info], outputs=[parallel_output]
                )

            # 4. Mood Tracker & Identity Timeline (Feature index shifted)
            with gr.TabItem("üß† Identity & Mood"):
                with gr.Row():
                    
                    # Mood Tracker Column (Aligned)
                    with gr.Column(scale=1):
                        gr.Markdown("### üòî Career Mood Tracker")
                        mood_selector = gr.Dropdown(
                            label="Current Mood",
                            choices=["Excited", "Bored", "Lost", "Ambitious", "Stressed", "Frustrated"],
                            value="Ambitious"
                        )
                        mood_intensity = gr.Slider(minimum=1, maximum=5, value=3, step=1, label="Intensity (1=Low, 5=High)")
                        mood_log_btn = gr.Button("Log Mood & Update Report", variant="secondary")
                        mood_output = gr.Markdown("### Mood Report\nLog your mood to see trends.")

                    # Identity Timeline Column (Aligned)
                    with gr.Column(scale=2):
                        gr.Markdown("### üìú Identity Timeline Builder")
                        timeline_type = gr.Dropdown(
                            label="Entry Type",
                            choices=["Childhood Interest", "Life Event", "Skill Acquisition", "Career Theme"],
                            value="Skill Acquisition"
                        )
                        timeline_entry = gr.Textbox(label="Timeline Entry Details", placeholder="e.g., 'Taught myself advanced Python on weekends' or 'Moved to a new city' (1-2 sentences)", lines=3)
                        
                        timeline_output = gr.Markdown("### Identity Synthesis\nSynthesized statement and data will appear here.", elem_id="timeline_builder_area")
                        
                mood_log_btn.click(
                    handle_mood_timeline,
                    inputs=[mood_selector, mood_intensity, timeline_entry, timeline_type],
                    outputs=[mood_output, timeline_output]
                )

            # 5. System Diagnostics (Observability)
            with gr.TabItem("üìä System Diagnostics"):
                with gr.Column(scale=1):
                    gr.Markdown("### ‚öôÔ∏è Agent Routing & Performance")
                    status_output = gr.Textbox(label="Observatory Report", lines=12, interactive=False, show_label=True, container=True, elem_id="status_report_box")
                    status_btn = gr.Button("üîÑ Refresh Status", variant="secondary")
                    context_output = gr.Textbox(label="üß† Current Memory Context (Last 50 Interactions)", lines=12, interactive=False, show_label=True, visible=False, container=True, elem_classes=["panel"])
                    gr.Markdown("""### ü§ñ Active Agent Roles\nThe Orchestrator automatically routes queries to a specialized role:
                    - **Resource Curator** (Learning Materials)
                    - **Q&A Specialist** (General Info/FAQs)
                    - **Career Advisor** (Guidance/Strategy)
                    - **Resume Specialist** (CV/Resume Optimization)
                    - **Interview Coach** (Preparation/Mock Interviews)
                    - **Career Simulator** (New Feature)
                    - **Parallel Career Generator** (New Feature)""", elem_classes=["agent-info"])

        # --- Event handlers ---
        msg.submit(chat_response, inputs=[msg, chatbot, agent_selector], outputs=[chatbot]).then(lambda: "", None, msg).then(get_status, outputs=[status_output])
        submit.click(chat_response, inputs=[msg, chatbot, agent_selector], outputs=[chatbot]).then(lambda: "", None, msg).then(get_status, outputs=[status_output])
        clear.click(clear_chat, outputs=[chatbot, status_output, context_output])
        status_btn.click(get_status, outputs=[status_output])
        view_context_btn.click(get_context, outputs=[context_output]).then(lambda v: gr.update(visible=not v), context_output, context_output)
        demo.load(get_status, outputs=[status_output])
    
    return demo

# --- Main function and execution ---

def main():
    print("\n" + "="*70)
    print("üöÄCareerMatrix AI (Multi-Agent System)")
    print("="*70)

    api_key = Config.GEMINI_API_KEY

    if not api_key:
        print("\n‚ö†Ô∏è GEMINI_API_KEY not found!")
        print("\nüìù Get your free API key at: https://makersuite.google.com/app/apikey")
        api_key = input("üîë Enter your Gemini API key (or press Enter to exit): ").strip()

        if not api_key:
            print("\n‚ùå No API key provided. Exiting...")
            return

    print("\n‚úÖ API Key configured")
    print("üîß Initializing Multi-Agent System...")
    print(" - Agents: Curator, Q&A, Advisor, Resume, Interview, Sandbox, Parallel")
    print(" - System Components: Orchestrator, Memory (Sessions & Context), Observatory (Logging/Metrics)")
    print("\nüåê Starting web interface...")
    print("="*70 + "\n")

    try:
        gr.close_all()
        print("üîÑ Closed previous instances")
    except:
        pass

    demo = create_interface(api_key)

    # Function to find an available port
    def find_free_port(start_port=7860, max_attempts=100):
        for port in range(start_port, start_port + max_attempts):
            try:
                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                sock.bind(('', port))
                sock.close()
                return port
            except OSError:
                continue
        return None

    port = find_free_port()
    if port is None:
        print("‚ö†Ô∏è Could not find available port. Using default...")
        port = 7860

    print(f"üîå Using port: {port}")

    demo.launch(
        share=True,
        server_name="0.0.0.0",
        server_port=port,
        show_error=True,
        quiet=False,
        prevent_thread_lock=False,
        inbrowser=False
    )


if __name__ == "__main__":
    main()
