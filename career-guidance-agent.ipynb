{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/hemakumaran/career-guidance-agent?scriptVersionId=282366740\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# **üöÄ CareerMatrix AI: A Multi-Agent Career Assistance System (Gemini 2.5 Flash)**\n\n\n## **üåü Executive Summary**\n\nCareerMatrix AI is a pioneering Multi-Agent System (MAS) architected to deliver highly specialized, contextual professional guidance. The platform‚Äôs core innovation is the Orchestrator, an AI routing engine that intelligently dispatches user queries to one of four expert agents. This architecture ensures uncompromised role specialization and superior efficiency. By integrating Longitudinal Memory (LTM) and experiential features like the Career Simulation Sandbox, CareerMatrix moves beyond stateless Q&A to become a long-term, adaptive career partner, built on the speed and versatility of Gemini 2.5 Flash.\n\n## **üë§ About the Developer & Team**\n\nTeam Lead: Hemasree K \n  #### *Institution    :Licet\n ####  *Location       :Chennai,Tamilnadu\n ####  *Current Status :Fresher\n\n**ü§ù Team Mates**\n\nTeam member 1: Thejaskumar K\n    *Institution    :MGR University\n    *Location       :Chennai,Tamilnady\n    *Current Status :BE,EEE \n    \nTeam member 2: Priyadharshini P\n    *Institution    :Kingston \n    *Location       :Vellore,Tamilnady\n    *Current Status :Fresher\n\nTeam member 2: Sudhakar P \n    *School         :National school\n    *Location       :Gudiyattam,Tamilnadu\n    *Current Status :12th\n    \n## **üöÄ What is CareerMatrix AI?**\n\nCareerMatrix AI is an advanced, specialized Multi-Agent System (MAS) built on Google Gemini 2.5 Flash and deployed via Gradio.\n\nIts core purpose is to provide highly accurate, context-aware, and actionable career guidance by routing user queries to the most qualified specialist. It transcends the limitations of monolithic chatbots by utilizing a cognitive architecture where multiple \"experts\" work in harmony, governed by a central Orchestrator.\n\n## **üß† System Architecture**\n\nThe design of CareerMatrix AI follows a robust, MLOps-ready architecture, organized into three key layers:\n\n1. The Agent Layer (The Experts)\nA collection of specialized LLM instances (e.g., Resume Specialist, Interview Coach) where each agent has a unique prompt, role, and output format tailored to a specific career domain.\n\n2. The Orchestration Layer (The Conductor)\nThe central Orchestrator component that intelligently receives the user's query and performs Heuristic Routing‚Äîanalyzing keywords and context to select the single best agent for the job, ensuring the most precise advice is given.\n\n3. The Observability & Memory Layer (The Foundation)\nThe Memory class stores all conversation history and session-specific data (Mood Log, Timeline). This provides the Context Engineering necessary for personalized advice.\n\nThe Observatory class tracks system health, logging agent usage, errors, and overall performance, essential for MLOps and reliability.\n\n![WF.png](attachment:88737be7-801b-41ab-b0f6-85ec4a7bfb09.png)\n\n## **ü§ù Meet the Agent Team**\n\nThe system is powered by six core agents, each ready to serve a different aspect of the user's career journey.\n\n### **1.Q&A Specialist**\n\nKey Functionality:General, comprehensive career questions and practical advice.\nExample Query:\"What is the future of AI in finance?\"\n\n### **2.Resource Curator**\n\nKey Functionality:Filters and recommends high-quality courses, articles, and books.\nExample Query:\"What are the best free courses to learn PyTorch?\"\n\n### **3.Career Advisor**\nKey Functionality:Personalized long-term guidance, path planning, and transition strategies.\nExample Query:\"How should I negotiate a 15% salary increase for a Senior ML role?\"\n\n### **4.Resume Specialist**\nKey Functionality:Review and optimization of resumes/CVs for ATS and clarity.\nExample Query:\"Review my CV and suggest improvements for a remote job.\"\n\n### **5.Interview Coach**\nKey Functionality:Preparation for technical and behavioral interviews.\nExample Query:\"Give me a mock interview for a Product Manager position.\"\n\n### **6.Career Simulator**\nKey Functionality:Runs a detailed, 1-week work-life simulation for any given job title.\nExample Query:\"Run a 1-week simulation for a startup CTO.\"\n\n### **7.Parallel Career Generator**\nKey Functionality:Hypothesizes three alternate career paths in different global realities.\nExample Query:\"Suggest three parallel careers based on my skills in coding and art.\"\n\n## **Core Features**\n\nCareerMatrix AI goes beyond basic Q&A by embedding specialized, high-value tools directly into the agent architecture.\n\n1. Multi-Agent Orchestration: The system's backbone, ensuring every query is routed to the optimal specialist (e.g., Resume, Interview, Advisor).\n\n2. Contextual Memory (Memory Class): Maintains conversation history and user-specific logs (mood, timeline entries) to provide truly personalized, long-term advice.\n\n3. üéÆ Career Simulation Sandbox: An immersive feature allowing users to role-play a one-week work cycle for any job title, detailing tasks, stress levels, and critical decision points.\n\n4. üåå Parallel Career Generator: A strategic feature that analyzes user data and suggests alternative career trajectories based on dramatic \"what-if\" scenarios (e.g., a drastically different economy).\n\n5. üìä Career Mood & Identity Tracker: Tools to log subjective career feelings and key life events, transforming disparate data into a Unified Identity Statement and an analytical Mood Report.\n\n6. System Observability: The Observatory tracks agent activity, errors, and performance, demonstrating production-ready MLOps practices.\n\n\n## **Technical Implementation**\n\nThe system is a Python-based Multi-Agent System (MAS) demonstrating advanced LLM engineering and robust software design.\n\n### Technical Stack\n\n* LLM Engine: Google Gemini 2.5 Flash\n\n* Front-end Framework: Gradio\n\n* Core Libraries: google-generativeai, os, sys, json, datetime\n\n* Architecture Pattern: Multi-Agent System (MAS) with Heuristic Routing\n\n### Design Principles\n\n* Object-Oriented Programming (OOP): Clear separation of concerns into distinct classes (Memory, Observatory, Orchestrator, BaseAgent) for modularity and maintainability.\n\n* Context Engineering: Each agent's prompt is dynamically augmented with recent conversation history and user profile data for relevant responses.\n\n* Robust Configuration: Secure loading of the GEMINI_API_KEY via Kaggle Secrets.\n\n* Custom UI/UX: Extensive use of CSS within Gradio to create a visually distinct, professional, and highly engaging interface.\n\n## **How to Use CareerMatrix AI**\n\nüñ•Ô∏è Web Interface with Gradio (Recommended)\n\nThe easiest and most engaging way to interact with the system is through the Gradio web interface launched below.\n\n## Why use the Gradio UI?\n\n* Immersive Experience: Access specialized feature tabs (Sandbox, Mood Tracker).\n\n* Agent Control: Easily override the Orchestrator's routing using the Specialized Agent Override dropdown.\n\n* Visual Feedback: Clear display of which agent answered your query (e.g., \"üë§ [Artheris - Resume Specialist]\").\n\nüíª Command Line Interface (Conceptual)\n\nWhile this notebook focuses on the Gradio UI, the underlying Python classes (CareerAssistanceSystem and Orchestrator) are designed to be callable programmatically, enabling easy integration into backend systems or terminal applications.\n\n## **Real-World Applications**\n\n1.Corporate L&D\n\nUse Case:Scaling personalized coaching for employees undergoing career transitions.\nAgent/Feature:Career Advisor, Resource Curator\n\n2.University Career Services\n\nUse Case:Providing 24/7 mock interviews and instant resume feedback to a large student body.\nAgent/Feature:Interview Coach, Resume Specialist\n\n3.HR/Recruitment Tech\n\nUse Case:Analyzing candidate profile statements (Timeline) to generate fast, accurate fit assessments.\nAgent/Feature:Identity Tracker, Parallel Career Generator\n\n## **Getting Started**\n\n### **Installation Steps**\n\nThe project requires only a few core Python packages, which are automatically installed at the start of the notebook if missing:\n\nInstallation is handled automatically in the first code cell:\nos.system(f\"{sys.executable} -m pip install -q google-generativeai gradio\")\n\n### **Prerequisite: Gemini API Key**\n\nThis system requires a Gemini API Key to run the LLM agents.\n\n## **Process to create a new API key in Google AI Studio**\n\n1.Navigate to Google AI Studio.\n\n2.Log in with your Google account.\n\n3.Click \"Create API Key\" and copy the generated key string.\n\n## **Process to add the created API key to Kaggle secrets**\n\n1.In your Kaggle notebook, click the Secrets tab (often located on the right side of the editor).\n\n2.Click \"Add a new secret.\"\n\n3.Set the Name of the secret to GEMINI_API_KEY (case-sensitive).\n\n4.Paste the key you copied from AI Studio into the Value field.\n\n5.Check the box to \"Attach\" the secret to the notebook.\n\n## **üëá Run the Cell Below to Launch Gradio Web Interface**\n\n**Note:** You are asked to add secrets to your notebook while you copy and edit the notebook. The system will automatically attempt to load the GEMINI_API_KEY from your attached secrets.\n\n\n\n## üíª Get Started\nSet your Gemini API Key as a Kaggle Secret named GEMINI_API_KEY.\n\n## Run the notebook cells.\n\nInteract with the Main Assistant or explore the advanced features in the dedicated tabs.\n\n\n\n\n","metadata":{}},{"cell_type":"code","source":"!pip install gradio google-generativeai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T10:28:27.989607Z","iopub.execute_input":"2025-11-28T10:28:27.989897Z","iopub.status.idle":"2025-11-28T10:28:38.35847Z","shell.execute_reply.started":"2025-11-28T10:28:27.989873Z","shell.execute_reply":"2025-11-28T10:28:38.357218Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.38.1)\nRequirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\nRequirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.11.0)\nRequirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.1.0)\nRequirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.116.1)\nRequirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.1)\nRequirement already satisfied: gradio-client==1.11.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.11.0)\nRequirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\nRequirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\nRequirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.36.0)\nRequirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\nRequirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.3)\nRequirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\nRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.11.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (25.0)\nRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.3)\nRequirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.3.0)\nCollecting pydantic<2.12,>=2.0 (from gradio)\n  Downloading pydantic-2.11.10-py3-none-any.whl.metadata (68 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\nRequirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\nRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.3)\nRequirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.5)\nRequirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\nRequirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\nRequirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.47.2)\nRequirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\nRequirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\nRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.15.0)\nRequirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (2025.10.0)\nRequirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (15.0.1)\nRequirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\nRequirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.28.1)\nRequirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.177.0)\nRequirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (6.33.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\nCollecting protobuf (from google-generativeai)\n  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nRequirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\nRequirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.5)\nCollecting cachetools<6.0,>=2.0.0 (from google-auth>=2.15.0->google-generativeai)\n  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.20.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\nCollecting pydantic-core==2.33.2 (from pydantic<2.12,>=2.0->gradio)\n  Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (14.2.0)\nRequirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\nRequirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.74.0)\nRequirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.0->gradio) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\nDownloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading pydantic-2.11.10-py3-none-any.whl (444 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m444.8/444.8 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cachetools-5.5.2-py3-none-any.whl (10 kB)\nInstalling collected packages: pydantic-core, protobuf, cachetools, pydantic\n  Attempting uninstall: pydantic-core\n    Found existing installation: pydantic_core 2.41.5\n    Uninstalling pydantic_core-2.41.5:\n      Successfully uninstalled pydantic_core-2.41.5\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 6.33.0\n    Uninstalling protobuf-6.33.0:\n      Successfully uninstalled protobuf-6.33.0\n  Attempting uninstall: cachetools\n    Found existing installation: cachetools 6.2.1\n    Uninstalling cachetools-6.2.1:\n      Successfully uninstalled cachetools-6.2.1\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 2.12.4\n    Uninstalling pydantic-2.12.4:\n      Successfully uninstalled pydantic-2.12.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed cachetools-5.5.2 protobuf-5.29.5 pydantic-2.11.10 pydantic-core-2.33.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install --upgrade google-generativeai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T10:28:38.360805Z","iopub.execute_input":"2025-11-28T10:28:38.361109Z","iopub.status.idle":"2025-11-28T10:28:42.344006Z","shell.execute_reply.started":"2025-11-28T10:28:38.361079Z","shell.execute_reply":"2025-11-28T10:28:42.342853Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\nRequirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\nRequirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.28.1)\nRequirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.177.0)\nRequirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\nRequirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.10)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.15.0)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\nRequirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\nRequirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.5)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\nRequirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.2)\nRequirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.74.0)\nRequirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.10.5)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport sys\nimport json\nimport gradio as gr\nfrom datetime import datetime\nfrom typing import List, Dict, Optional\nimport socket\nimport time \nimport random \n\n# Install required packages if not available\ndef install_packages():\n    try:\n        import google.generativeai as genai\n    except ImportError:\n        # Simplified installation for execution\n        print(\"üì¶ Installing required packages...\")\n        os.system(f\"{sys.executable} -m pip install -q google-generativeai gradio\")\n        import google.generativeai as genai\n    return genai\n\ngenai = install_packages()\n\n# --- Config and Utility Classes ---\n\nclass Config:\n    GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\", \"\")\n    try:\n        from kaggle_secrets import UserSecrets\n        user_secrets = UserSecrets()\n        if not GEMINI_API_KEY:\n            GEMINI_API_KEY = user_secrets.get_secret(\"GEMINI_API_KEY\")\n        print(\"‚úÖ API Key loaded from Kaggle Secrets (if applicable)\")\n    except ImportError:\n        pass\n\n    MODEL_NAME = \"gemini-2.5-flash\"\n    MAX_MEMORY_SIZE = 50 \n    AGENT_CHOICES = {\n        \"Auto (Smart Routing)\": None,\n        \"Resource Curator\": \"curator\",\n        \"Q&A Specialist\": \"qa\",\n        \"Career Advisor\": \"advisor\",\n        \"Resume Specialist\": \"resume\",\n        \"Interview Coach\": \"interview\"\n    }\n\nclass Memory:\n    \"\"\"\n    Sessions & State Management / Context Engineering\n    Stores conversation history and session data (Mood/Timeline).\n    \"\"\"\n    def __init__(self, max_size: int = Config.MAX_MEMORY_SIZE):\n        self.conversations: List[Dict] = []\n        self.max_size = max_size\n        self.session_data: Dict = {\"mood_log\": [], \"timeline_data\": []}\n\n    def add_interaction(self, role: str, content: str, agent: str = \"system\"):\n        self.conversations.append({\n            \"timestamp\": datetime.now().isoformat(),\n            \"role\": role,\n            \"content\": content,\n            \"agent\": agent\n        })\n        if len(self.conversations) > self.max_size:\n            self.conversations = self.conversations[-self.max_size:]\n\n    def get_context(self, last_n: int = 10) -> str:\n        \"\"\"Context Engineering: Returns the most recent N interactions.\"\"\"\n        recent = self.conversations[-last_n:]\n        return \"\\n\".join([f\"{msg['role']} ({msg['agent']}): {msg['content']}\" for msg in recent])\n\n    def update_session_data(self, key: str, value):\n        self.session_data[key] = value\n\n    def get_session_data(self, key: str, default=None):\n        return self.session_data.get(key, default)\n    \n    def log_mood(self, mood: str, intensity: int):\n        self.session_data.setdefault(\"mood_log\", []).append({\n            \"timestamp\": datetime.now().isoformat(),\n            \"mood\": mood,\n            \"intensity\": intensity\n        })\n\n    def clear(self):\n        self.conversations = []\n        self.session_data = {\"mood_log\": [], \"timeline_data\": []}\n\nclass BaseAgent:\n    \"\"\"Base class for all LLM-powered agents.\"\"\"\n    def __init__(self, name: str, role: str, model):\n        self.name = name\n        self.role = role\n        self.model = model\n\n    def process(self, query: str, context: str = \"\") -> str:\n        \"\"\"Agent powered by an LLM: Core generation logic.\"\"\"\n        raise NotImplementedError\n\n# --- Core LLM-Powered Agents (Parallel Agents) ---\n\nclass CuratorAgent(BaseAgent):\n    def __init__(self, model): super().__init__(\"Artheris\", \"Resource Curator\", model)\n    def process(self, query: str, context: str = \"\") -> str:\n        prompt = f\"\"\"You are a Career Resource Curator. Provide curated resources, articles, courses, and materials. Context: {context}\\nQuery: {query}\\nProvide structured, actionable resource recommendations with links where possible.\"\"\"\n        try: return self.model.generate_content(prompt).text\n        except Exception as e: return f\"Error: {str(e)}\"\n\nclass QAAgent(BaseAgent):\n    def __init__(self, model): super().__init__(\"Artheris\", \"Q&A Specialist\", model)\n    def process(self, query: str, context: str = \"\") -> str:\n        prompt = f\"\"\"You are a Career Q&A Specialist. Answer career questions accurately with actionable advice. Context: {context}\\nQuery: {query}\\nProvide a comprehensive, practical answer.\"\"\"\n        try: return self.model.generate_content(prompt).text\n        except Exception as e: return f\"Error: {str(e)}\"\n\nclass CareerAdvisorAgent(BaseAgent):\n    def __init__(self, model): super().__init__(\"Artheris\", \"Career Advisor\", model)\n    def process(self, query: str, context: str = \"\") -> str:\n        prompt = f\"\"\"You are a Professional Career Advisor. Provide personalized guidance, career paths, and development strategies. Context: {context}\\nQuery: {query}\\nProvide thoughtful, strategic career advice.\"\"\"\n        try: return self.model.generate_content(prompt).text\n        except Exception as e: return f\"Error: {str(e)}\"\n\nclass ResumeAgent(BaseAgent):\n    def __init__(self, model): super().__init__(\"Artheris\", \"Resume Specialist\", model)\n    def process(self, query: str, context: str = \"\") -> str:\n        prompt = f\"\"\"You are a Resume Optimization Specialist. Review resumes, provide improvements, and optimize for ATS. Context: {context}\\nQuery: {query}\\nProvide specific, actionable resume improvement guidance.\"\"\"\n        try: return self.model.generate_content(prompt).text\n        except Exception as e: return f\"Error: {str(e)}\"\n\nclass InterviewAgent(BaseAgent):\n    def __init__(self, model): super().__init__(\"Artheris\", \"Interview Coach\", model)\n    def process(self, query: str, context: str = \"\") -> str:\n        prompt = f\"\"\"You are an Interview Preparation Coach. Prepare candidates with questions, answers, and strategies. Context: {context}\\nQuery: {query}\\nProvide practical interview preparation guidance.\"\"\"\n        try: return self.model.generate_content(prompt).text\n        except Exception as e: return f\"Error: {str(e)}\"\n\n# --- NEW FEATURE AGENTS/LOGIC ---\n\nclass SandboxAgent(BaseAgent):\n    def __init__(self, model):\n        super().__init__(\"Artheris\", \"Career Simulator\", model)\n\n    def process(self, job_title: str) -> str:\n        \n        prompt = f\"\"\"\n        **Career Simulation Sandbox - 1 Week in the Life of a {job_title}**\n        Act as an unbiased simulator. Detail a typical work week (Monday to Friday) for a person in the '{job_title}' role.\n        For each day, describe:\n        1. **Key Tasks/Projects:** (e.g., meetings, coding, analysis, client calls).\n        2. **Major Decision Point:** Present a realistic dilemma the user must solve.\n        3. **Stress Level:** (Low/Medium/High).\n        Format the response clearly using Markdown headings for each day.\n        End with a summary of the weekly outcomes and a thought-provoking conclusion.\"\"\"\n        try:\n            response = self.model.generate_content(prompt).text\n            return response\n        except Exception as e:\n            return f\"Error running simulation: {str(e)}\"\n\nclass ParallelUniverseAgent(BaseAgent):\n    def __init__(self, model):\n        super().__init__(\"Artheris\", \"Parallel Career Generator\", model)\n\n    def process(self, current_info: str, context: str) -> str:\n        \n        prompt = f\"\"\"\n        **Parallel Universe Career Generator**\n        Analyze the user's information and current career context, then hypothesize career paths if they were operating in a dramatically different economy or nation.\n        User Context: {current_info}\n        Current Conversation Context: {context}\n        Suggest **three distinct parallel career trajectories**. For each trajectory, detail:\n        1. **Parallel Reality:** (The 'What If...').\n        2. **Suggested Role:** (The specific job title).\n        3. **Required Adaptation:** (The key skill or mindset change needed).\n        Provide creative, insightful, and strategic suggestions.\"\"\"\n        try:\n            response = self.model.generate_content(prompt).text\n            return response\n        except Exception as e:\n            return f\"Error generating parallel careers: {str(e)}\"\n\n# --- Observatory, Orchestrator, and CareerAssistanceSystem ---\n\nclass Observatory:\n    \"\"\"Observability: Tracks metrics, logs events, and provides a status report.\"\"\"\n    def __init__(self, logs: List[Dict] = None):\n        self.logs: List[Dict] = logs if logs is not None else []\n        self.metrics: Dict = {\"total_queries\": 0, \"agent_calls\": {}, \"errors\": 0}\n        self.start_time = datetime.now()\n        \n    def log_event(self, event_type: str, agent: str, details: str):\n        self.logs.append({\"timestamp\": datetime.now().isoformat(), \"type\": event_type, \"agent\": agent, \"details\": details})\n        if event_type == \"query\":\n            self.metrics[\"total_queries\"] += 1\n            if agent not in self.metrics[\"agent_calls\"]: self.metrics[\"agent_calls\"][agent] = 0\n            self.metrics[\"agent_calls\"][agent] += 1\n        elif event_type == \"error\":\n            self.metrics[\"errors\"] += 1\n\n    def get_report(self) -> str:\n        uptime = datetime.now() - self.start_time\n        uptime_str = str(uptime).split('.')[0]\n        report = f\"\"\"=== System Observatory Report ===\\nUptime: {uptime_str}\\nTotal Queries: {self.metrics['total_queries']}\\nTotal Errors: {self.metrics['errors']}\\nAgent Activity:\\n\"\"\"\n        if self.metrics[\"agent_calls\"]:\n            for agent, calls in self.metrics[\"agent_calls\"].items(): report += f\" - {agent}: {calls} calls\\n\"\n        else: report += \" - No calls recorded yet.\\n\"\n        report += f\"\\nRecent Events (last 5):\\n\"\n        for log in self.logs[-5:]: report += f\"[{log['timestamp'].split('T')[1].split('.')[0]}] {log['type']} - {log['agent']}: {log['details']}\\n\"\n        return report\n\nclass Orchestrator:\n    \"\"\"Coordinates agents and routes queries in the Multi-Agent System.\"\"\"\n    def __init__(self, agents: Dict[str, BaseAgent], memory: Memory, observatory: Observatory):\n        self.agents = agents\n        self.memory = memory\n        self.observatory = observatory\n\n    def route_query(self, query: str) -> str:\n        \"\"\"Heuristic-based routing to select the best parallel agent.\"\"\"\n        query_lower = query.lower()\n        if any(w in query_lower for w in [\"resource\", \"article\", \"learn\", \"course\", \"material\", \"book\"]): return \"curator\"\n        elif any(w in query_lower for w in [\"resume\", \"cv\", \"curriculum vitae\", \"optimize my resume\"]): return \"resume\"\n        elif any(w in query_lower for w in [\"interview\", \"mock interview\", \"interview prep\", \"behavioral question\", \"tell me about yourself\"]): return \"interview\"\n        elif any(w in query_lower for w in [\"advice\", \"guidance\", \"career path\", \"transition\", \"switch\", \"salary negotiation\", \"long-term strategy\"]): return \"advisor\"\n        else: return \"qa\"\n\n    def process_query(self, query: str, manual_agent_key: Optional[str] = None) -> str:\n        self.observatory.log_event(\"query\", \"orchestrator\", f\"Received: {query[:50]}...\")\n        \n        agent_key = manual_agent_key if manual_agent_key and manual_agent_key in self.agents else self.route_query(query)\n        agent = self.agents.get(agent_key)\n        if not agent: return \"Error: Could not route query to appropriate agent.\"\n\n        context = self.memory.get_context(last_n=10)\n        self.observatory.log_event(\"routing\", \"orchestrator\", f\"Routed to {agent.role}\")\n        \n        response = agent.process(query, context)\n        \n        self.memory.add_interaction(\"user\", query)\n        self.memory.add_interaction(\"assistant\", response, agent.name)\n        self.observatory.log_event(\"response\", agent.name, f\"Response length: {len(response)} chars\")\n\n        return f\"**üë§ [{agent.name} - {agent.role}]**\\n\\n{response}\"\n\n\nclass CareerAssistanceSystem:\n    \"\"\"The main system managing the Multi-Agent System, Memory, and Observatory.\"\"\"\n    def __init__(self):\n        # API Key is assumed configured globally or handled by Gradio\n        self.model = genai.GenerativeModel(Config.MODEL_NAME)\n        self.memory = Memory()\n        self.observatory = Observatory()\n        self.agents = {\n            # Core Parallel Agents\n            \"curator\": CuratorAgent(self.model),\n            \"qa\": QAAgent(self.model),\n            \"advisor\": CareerAdvisorAgent(self.model),\n            \"resume\": ResumeAgent(self.model),\n            \"interview\": InterviewAgent(self.model),\n            # Feature Agents\n            \"sandbox\": SandboxAgent(self.model), \n            \"parallel\": ParallelUniverseAgent(self.model)\n        }\n        self.orchestrator = Orchestrator(self.agents, self.memory, self.observatory)\n\n    def process_message(self, message: str, history: List, manual_agent_key: Optional[str] = None) -> str:\n        try:\n            return self.orchestrator.process_query(message, manual_agent_key)\n        except Exception as e:\n            self.observatory.log_event(\"error\", \"system\", str(e))\n            return f\"‚ö†Ô∏è Error: {str(e)}\"\n    \n    # --- New Feature Methods ---\n    def run_sandbox(self, job_title: str):\n        return self.agents[\"sandbox\"].process(job_title)\n\n    def run_parallel(self, user_info: str):\n        context = self.memory.get_context(last_n=20)\n        return self.agents[\"parallel\"].process(user_info, context)\n\n    def log_mood_and_get_timeline(self, mood: str, intensity: int, timeline_entry: str, timeline_type: str):\n        self.memory.log_mood(mood, intensity)\n        \n        if timeline_entry:\n             self.memory.session_data.setdefault(\"timeline_data\", []).append({\n                 \"timestamp\": datetime.now().isoformat(),\n                 \"type\": timeline_type,\n                 \"entry\": timeline_entry\n             })\n        \n        mood_report = self.generate_mood_report()\n        timeline_visualization = self.generate_timeline_visualization()\n        \n        return mood_report, timeline_visualization\n\n    def generate_mood_report(self):\n        log = self.memory.get_session_data(\"mood_log\", [])\n        if not log:\n            return \"No mood data logged yet.\"\n        \n        latest_mood = log[-1]\n        mood_counts = {}\n        for entry in log:\n            mood_counts[entry['mood']] = mood_counts.get(entry['mood'], 0) + 1\n            \n        report = f\"### üìä Career Mood Tracker Report\\n\"\n        report += f\"**Latest Mood:** {latest_mood['mood']} (Intensity: {latest_mood['intensity']}/5) at {latest_mood['timestamp'].split('T')[0]}\\n\"\n        report += f\"**Mood Frequency (Total {len(log)} logs):**\\n\"\n        for mood, count in mood_counts.items():\n            report += f\"- {mood}: {count} times\\n\"\n        \n        prompt = f\"Analyze the following mood log (Mood: {mood_counts}) and provide a brief, professional interpretation of the user's emotional pattern regarding their career.\"\n        interpretation = self.model.generate_content(prompt).text\n        report += f\"\\n**Professional Interpretation:** {interpretation}\"\n        return report\n\n    def generate_timeline_visualization(self):\n        data = self.memory.get_session_data(\"timeline_data\", [])\n        if not data:\n            return \"No identity timeline data logged yet.\"\n\n        vis = \"### üìú Identity Timeline Builder Data\\n\"\n        for entry in data:\n            vis += f\"**[{entry['timestamp'].split('T')[0]}]** - **{entry['type']}**:\\n > {entry['entry']}\\n\"\n            \n        prompt = f\"Based on the following life events, interests, and skills ({json.dumps(data)}), generate a single, unified career Identity Statement (3 sentences max).\"\n        identity_statement = self.model.generate_content(prompt).text\n        vis += f\"\\n**Unified Identity Statement:** {identity_statement}\"\n        return vis\n\n    def get_system_status(self) -> str:\n        return self.observatory.get_report()\n\n    def get_memory_context(self) -> str:\n        return self.memory.get_context(last_n=Config.MAX_MEMORY_SIZE)\n\n    def clear_memory(self):\n        self.memory.clear()\n\n\n# --- GRADIO INTERFACE CREATION (MODIFIED) ---\n\ndef create_interface(api_key: str):\n    \n    # Ensure API key is configured before creating the system instance\n    genai.configure(api_key=api_key) \n    system = CareerAssistanceSystem()\n\n    def chat_response(message, history, agent_override):\n        if not message.strip(): return history\n        agent_key = Config.AGENT_CHOICES.get(agent_override)\n        yield history + [{\"role\": \"user\", \"content\": message}, {\"role\": \"assistant\", \"content\": \"...\"}]\n        \n        response = system.process_message(message, history, agent_key) \n        \n        new_history = history + [{\"role\": \"user\", \"content\": message}, {\"role\": \"assistant\", \"content\": response}]\n        yield new_history\n\n    def get_status(): return system.get_system_status()\n    def get_context(): return system.get_memory_context()\n    def clear_chat():\n        system.clear_memory()\n        return [], system.get_system_status(), gr.update(visible=False)\n\n    def handle_mood_timeline(mood, intensity, timeline_entry, timeline_type):\n        return system.log_mood_and_get_timeline(mood, intensity, timeline_entry, timeline_type)\n    \n    def simulate_sandbox(job_title):\n        yield \"...\"\n        response = system.run_sandbox(job_title)\n        yield response\n        \n    def generate_parallel(user_info):\n        yield \"...\"\n        response = system.run_parallel(user_info)\n        yield response\n\n    # --- ADVANCED, IMMERSIVE CUSTOM CSS STYLING (UPDATED FOR DARK BLUE SUB-HEADING) ---\n    custom_css = \"\"\"\n    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@400;600;700;800&family=Poppins:wght@300;400;500;600;700&display=swap');\n    \n    :root {\n        /* Consistent Color Palette */\n        --career-primary: #5E35B1; /* Deep Violet (Used for Primary/Buttons) */\n        --career-accent: #FF8A65;  /* Coral/Orange Accent (Used for CTA/Logo Border/Glow/Gradient Start) */\n        --career-secondary: #4DB6AC; /* Teal/Mint Secondary */\n        --career-text-dark: #212121;\n        --career-text-light: #ffffff;\n        --career-surface: #ffffff;\n        --career-background-gradient-start: #ECEFF1;\n        --career-background-gradient-end: #CFD8DC;\n        --neon-glow: 0 0 8px var(--career-accent), 0 0 20px rgba(255, 138, 101, 0.7);\n        --soft-shadow: 0 12px 30px rgba(0, 0, 0, 0.18);\n        --border-radius-large: 20px;\n        --border-radius-small: 10px;\n        --transition-speed: 0.3s;\n        \n        /* NEW SKY BLUE COLOR FOR MARQUEE */\n        --sky-blue: #87CEEB; \n    }\n\n    .gradio-container {\n        font-family: 'Poppins', sans-serif;\n        background: linear-gradient(135deg, var(--career-background-gradient-start) 0%, var(--career-background-gradient-end) 100%) !important;\n        padding: 30px;\n    }\n    \n    /* --- HEADER SECTION (Purple/Teal Gradient Background) --- */\n    .header-bar {\n        display: flex; align-items: center; gap: 30px; padding: 25px 35px;\n        background: linear-gradient(135deg, var(--career-primary) 0%, #7E57C2 50%, var(--career-secondary) 100%);\n        color: var(--career-text-light); border-radius: var(--border-radius-large);\n        box-shadow: 0 15px 35px rgba(0, 0, 0, 0.4); margin-bottom: 30px;\n    }\n    \n    /* --- LOGO ZOOM-IN ANIMATION STYLES --- */\n    .logo-image {\n        width: 150px; height: 150px; border-radius: 50%; border: 6px solid var(--career-accent);\n        box-shadow: var(--neon-glow); flex-shrink: 0; object-fit: cover;\n        \n        /* Initial state for animation */\n        opacity: 0; \n        transform: scale(0.1);\n        \n        /* Animation application */\n        animation: zoomIn 1.5s cubic-bezier(0.25, 0.46, 0.45, 0.94) forwards;\n    }\n\n    @keyframes zoomIn {\n        0% {\n            transform: scale(0.1); \n            opacity: 0;\n        }\n        60% {\n            transform: scale(1.1); /* Slight overshoot */\n            opacity: 1;\n        }\n        100% {\n            transform: scale(1.0);\n            opacity: 1;\n        }\n    }\n    \n    /* --- MAIN HEADING (H1) STYLES --- */\n    .header-bar h1 {\n        font-family: 'Montserrat', sans-serif; \n        font-weight: 800; \n        font-size: 3.5em; \n        margin: 0;\n        letter-spacing: 1px;\n        color: var(--career-text-light); /* Base white text color */\n        \n        /* Fixed, non-shaking state */\n        transform: scale(1);\n        text-shadow: 0 0 5px rgba(255,255,255,0.7), 0 0 10px rgba(255,255,255,0.5); \n        \n        /* ONLY KEEP glowPulse */\n        animation: \n            glowPulse 3s infinite alternate ease-in-out; \n    }\n\n    /* Keyframes for soft glowing pulse (KEPT) */\n    @keyframes glowPulse {\n        0% {\n            text-shadow: 0 0 5px rgba(255,255,255,0.7), 0 0 10px rgba(255,255,255,0.5), 0 0 15px rgba(255,255,255,0.3);\n        }\n        50% {\n            text-shadow: 0 0 10px rgba(255,255,255,1), 0 0 20px rgba(255,255,255,0.8), 0 0 30px rgba(255,255,255,0.6), 0 0 40px rgba(255, 138, 101, 0.4); /* Adding a subtle accent glow */\n        }\n        100% {\n            text-shadow: 0 0 5px rgba(255,255,255,0.7), 0 0 10px rgba(255,255,255,0.5), 0 0 15px rgba(255,255,255,0.3);\n        }\n    }\n\n    /* --- SUB-HEADING (H3) STYLES (UPDATED TO DARK BLUE) --- */\n    .header-bar h3 {\n        font-family: 'Poppins', sans-serif; \n        font-weight: 500;\n        margin: 5px 0 0 0; \n        font-size: 1.3em; \n        opacity: 1; \n        \n        /* Solid Dark Blue Color */\n        color: #000080; /* Dark blue color */\n        background-image: none; /* Remove gradient */\n        -webkit-background-clip: unset; /* Reset background-clip */\n        background-clip: unset; /* Reset background-clip */\n        \n        text-shadow: none; \n    }\n\n    /* --- HORIZONTAL MARQUEE STYLES (SKY BLUE) --- */\n    \n    .marquee-container {\n        width: 100%; \n        overflow: hidden; \n        padding: 10px 0;\n        margin-top: 15px; \n        border-radius: var(--border-radius-small);\n        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);\n    }\n    .marquee-container.horizontal {\n        background-color: var(--sky-blue); \n        color: white;\n    }\n\n    .animated-text {\n        font-size: 1.2em;\n        font-weight: 700;\n        white-space: nowrap; \n        display: inline-block;\n        padding: 0 10px;\n    }\n\n    .horizontal-move {\n        transform: translateX(100%); \n        animation: move-horizontal 15s linear infinite;\n    }\n\n    @keyframes move-horizontal {\n        0% {\n            transform: translateX(100%); \n        }\n        100% {\n            transform: translateX(-100%); \n        }\n    }\n\n    /* --- GENERAL ALIGNMENT & CARD STYLING --- */\n    .gradio-container .panel, .gradio-container .gr-tab {\n        background-color: var(--career-surface);\n        border-radius: var(--border-radius-large);\n        box-shadow: var(--soft-shadow);\n        padding: 30px;\n        transition: transform var(--transition-speed) ease, box-shadow var(--transition-speed) ease;\n        border: none;\n    }\n    .gradio-container .panel:hover {\n        transform: translateY(-4px); \n        box-shadow: 0 18px 45px rgba(0, 0, 0, 0.2);\n    }\n    \n    /* Perfect Alignment for Rows in the Chat Tab */\n    .gradio-container .gr-row {\n        align-items: flex-end;\n    }\n\n    /* --- TAB ENHANCEMENTS --- */\n    .gr-tab-button {\n        font-weight: 600;\n        color: #757575; /* Default inactive color */\n        transition: color var(--transition-speed) ease, background-color 0.2s ease;\n        padding: 12px 20px !important;\n        border-radius: var(--border-radius-small) var(--border-radius-small) 0 0 !important;\n    }\n    .gr-tab-button:hover {\n        background-color: #f0f4f7 !important; /* Light hover background */\n        color: var(--career-primary) !important;\n    }\n    .gr-tab-button.selected {\n        color: var(--career-primary) !important;\n        background-color: var(--career-surface) !important;\n        border-bottom: 3px solid var(--career-primary) !important;\n    }\n    \n    /* --- INPUT & BUTTON CONSISTENCY --- */\n    .gr-input, .gr-textbox, .gr-dropdown, .gr-slider {\n        border-radius: var(--border-radius-small) !important;\n        border: 1px solid #ddd;\n        transition: border-color 0.2s, box-shadow 0.2s;\n        padding: 10px 15px !important;\n    }\n    \n    /* Input Focus Glow */\n    .gr-input:focus-within, \n    .gr-textbox:focus-within, \n    .gr-dropdown.open, \n    .gr-slider-fill { \n        border-color: var(--career-primary) !important;\n        box-shadow: 0 0 0 4px rgba(94, 53, 177, 0.25); /* Stronger glow effect */\n    }\n    \n    /* Button Styling */\n    .gr-button {\n        border-radius: var(--border-radius-small) !important;\n        font-weight: 600 !important;\n        padding: 12px 20px !important;\n        transition: all var(--transition-speed) ease;\n    }\n    .gr-button.primary {\n        background-color: var(--career-primary) !important;\n    }\n    .gr-button.primary:hover {\n        background-color: #512DA8 !important; \n    }\n    .gr-button.secondary {\n        background-color: #F0F4F7 !important;\n        color: var(--career-text-dark) !important;\n        border: 1px solid #CFD8DC !important;\n    }\n    .gr-button.secondary:hover {\n        background-color: #E0E5E9 !important;\n        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n    }\n\n    /* --- CHATBOT MESSAGES --- */\n    .message.bot {\n        background-color: #F0F4F7 !important; \n        border-top-left-radius: 0 !important;\n        padding: 15px; \n    }\n    .message.user {\n        background-color: var(--career-secondary) !important;\n        color: var(--career-text-light) !important;\n        border-top-right-radius: 0 !important;\n    }\n\n    /* --- CTA BUTTON (Neon Glow & Pulse) --- */\n    #cta_button {\n        /* Core Style */\n        border-radius: 12px; \n        font-size: 1.2em;\n        font-weight: 700;\n        padding: 18px 35px;\n        \n        /* 3D/Neon/Reflection */\n        background: var(--career-accent);\n        color: var(--career-text-light);\n        border: 2px solid var(--career-accent);\n        text-shadow: 0 0 2px rgba(0, 0, 0, 0.3);\n        box-shadow: var(--neon-glow), 0 8px 15px rgba(0, 0, 0, 0.3); \n        position: relative;\n        overflow: hidden;\n        z-index: 1;\n        \n        /* Continuous Pulse Animation */\n        animation: pulse 2s infinite ease-in-out;\n    }\n    \n    /* Keyframes for the Pulse/Breathing Effect */\n    @keyframes pulse {\n        0% {\n            box-shadow: var(--neon-glow), 0 0 0 0 rgba(255, 138, 101, 0.7);\n        }\n        50% {\n            box-shadow: var(--neon-glow), 0 0 0 15px rgba(255, 138, 101, 0); \n        }\n        100% {\n            box-shadow: var(--neon-glow), 0 0 0 0 rgba(255, 138, 101, 0.7);\n        }\n    }\n    \n    /* Reflection and Hover styles remain the same for depth */\n    #cta_button::before {\n        content: '';\n        position: absolute;\n        top: 0; left: 0; width: 100%; height: 100%;\n        background: radial-gradient(circle at 10% 20%, rgba(255,255,255,0.4) 0%, rgba(255,255,255,0) 60%);\n        opacity: 0.7;\n        pointer-events: none;\n        z-index: 2;\n    }\n    \n    #cta_button:hover {\n        transform: scale(1.02) translateY(-4px); \n        border-color: #ffffff;\n        box-shadow: var(--neon-glow), 0 10px 25px rgba(0, 0, 0, 0.5);\n    }\n    #cta_button:active {\n        transform: scale(0.99); \n        box-shadow: inset 0 3px 8px rgba(0, 0, 0, 0.3);\n    }\n    \n    /* --- SCROLLBAR STYLING --- */\n    ::-webkit-scrollbar {\n        width: 10px;\n        height: 10px;\n    }\n    \n    ::-webkit-scrollbar-track {\n        background: #f0f4f7; \n        border-radius: 5px;\n    }\n    \n    ::-webkit-scrollbar-thumb {\n        background: var(--career-secondary); \n        border-radius: 5px;\n    }\n    \n    ::-webkit-scrollbar-thumb:hover {\n        background: #388E81; \n    }\n    \n    /* --- UI ELEMENTS for Feature Tabs --- */\n    \n    #timeline_builder_area {\n        background-color: #f7f9fb !important;\n        border-left: 5px solid var(--career-secondary) !important; \n        padding-left: 20px;\n        white-space: pre-wrap;\n        border-radius: var(--border-radius-small);\n    }\n    \n    .gr-slider-fill {\n        background: linear-gradient(90deg, #FFCDD2 0%, var(--career-accent) 100%) !important;\n        border-radius: 50px;\n    }\n    .gr-slider-thumb {\n        background-color: var(--career-primary) !important;\n        border: 2px solid var(--career-text-light) !important;\n        box-shadow: 0 0 5px rgba(0, 0, 0, 0.3);\n    }\n\n    #status_report_box, .agent-info {\n        margin-top: 15px;\n    }\n    \n    \"\"\"\n    # ------------------------------------------\n    \n    with gr.Blocks(theme=gr.themes.Soft(), title=\"Career Assistance AI\", css=custom_css) as demo:\n\n        # --- HEADER SECTION (Logo, Title) ---\n        with gr.Row(elem_classes=[\"header-bar\"]):\n            gr.Image(value=r\"https://img.freepik.com/premium-photo/gradient-hacker-logo-template_1029473-588573.jpg?semt=ais_hybrid&w=740&q=80\", label=\"AI Logo\", width=150, height=180, container=False, elem_classes=[\"logo-image\"])\n            with gr.Column(elem_classes=[\"header-text\"]):\n                # The h1 content is animated via the CSS\n                gr.Markdown(\"<h1>CareerMatrix AI</h1><h3>Multi-Agent Career Assistance System</h3>\")\n\n        # --- MAIN INTERFACE TABS ---\n        with gr.Tabs(elem_classes=[\"panel\"]):\n            \n            # 1. Main Chat Assistant\n            with gr.TabItem(\"üí¨ Main Assistant\"):\n                \n                # --- ANIMATED MARQUEE BANNER INTEGRATION ---\n                gr.Markdown(\n                    '<div class=\"marquee-container horizontal\"><p class=\"animated-text horizontal-move\">‚òÖ CareerMatrix AI is guiding your path to success! ‚òÖ Utilize our specialized agents for optimal advice. ‚òÖ</p></div>',\n                    sanitize_html=True \n                )\n                \n                with gr.Row():\n                    with gr.Column(scale=3):\n                        chatbot = gr.Chatbot(height=500, label=\"Artheris - Multi-Agent Chat\", show_label=True, avatar_images=(None, \"ü§ñ\"), type=\"messages\")\n                        with gr.Row():\n                            agent_selector = gr.Dropdown(label=\"Specialized Agent Override\", choices=list(Config.AGENT_CHOICES.keys()), value=\"Auto (Smart Routing)\", scale=1, interactive=True)\n                            msg = gr.Textbox(label=\"Ask a Question\", placeholder=\"e.g., 'Review my resume' or 'What are the steps for a career transition?'\", scale=4, lines=2)\n                            submit = gr.Button(\"üöÄ Send\", scale=1, variant=\"primary\")\n                        with gr.Row():\n                            clear = gr.Button(\"üóëÔ∏è Clear Conversation & Memory\", variant=\"secondary\")\n                            view_context_btn = gr.Button(\"üß† Toggle Memory Context\", variant=\"secondary\")\n                        with gr.Accordion(\"üìö Key Agent Commands\", open=False):\n                             gr.Markdown(\"- **Resource Curator:** `best resources to learn Python`\\n- **Resume Specialist:** `review my CV for an analyst role`\\n- **Interview Coach:** `common interview questions for product managers`\\n- **Career Advisor:** `advice on transitioning to cybersecurity`\\n- **Q&A Specialist:** `What is the salary range for a UX designer?`\")\n\n            # 2. Career Simulation Sandbox\n            with gr.TabItem(\"üéÆ Career Simulation Sandbox\"):\n                with gr.Column():\n                    gr.Markdown(\"## üßë‚Äçüíª Simulate 1 Week on the Job\")\n                    job_input = gr.Textbox(label=\"Job Title to Simulate\", placeholder=\"e.g., 'Senior Data Scientist' or 'Startup CTO'\", lines=1)\n                    simulate_btn = gr.Button(\"‚ñ∂Ô∏è Run 1-Week Simulation\", variant=\"primary\", elem_id=\"cta_button\")\n                    simulation_output = gr.Markdown(\"### Simulation Results\\nSimulated tasks, stress level, and key decisions will appear here.\")\n                \n                simulate_btn.click(\n                    simulate_sandbox, inputs=[job_input], outputs=[simulation_output]\n                )\n                job_input.submit(\n                    simulate_sandbox, inputs=[job_input], outputs=[simulation_output]\n                )\n\n            # 3. Parallel Universe Career Generator (Feature index shifted)\n            with gr.TabItem(\"üåå Parallel Universe\"):\n                with gr.Column():\n                    gr.Markdown(\"## üëΩ What If? Career Generator\")\n                    parallel_info = gr.Textbox(label=\"Your Current Skills/Location\", placeholder=\"e.g., 'Software Engineer in Tokyo with a focus on green tech'\", lines=3)\n                    parallel_btn = gr.Button(\"‚ú® Generate Parallel Careers\", variant=\"secondary\")\n                    parallel_output = gr.Markdown(\"### Parallel Career Trajectories\\nSuggestions based on alternative economic realities will appear here.\")\n                \n                parallel_btn.click(\n                    generate_parallel, inputs=[parallel_info], outputs=[parallel_output]\n                )\n                parallel_info.submit(\n                    generate_parallel, inputs=[parallel_info], outputs=[parallel_output]\n                )\n\n            # 4. Mood Tracker & Identity Timeline (Feature index shifted)\n            with gr.TabItem(\"üß† Identity & Mood\"):\n                with gr.Row():\n                    \n                    # Mood Tracker Column (Aligned)\n                    with gr.Column(scale=1):\n                        gr.Markdown(\"### üòî Career Mood Tracker\")\n                        mood_selector = gr.Dropdown(\n                            label=\"Current Mood\",\n                            choices=[\"Excited\", \"Bored\", \"Lost\", \"Ambitious\", \"Stressed\", \"Frustrated\"],\n                            value=\"Ambitious\"\n                        )\n                        mood_intensity = gr.Slider(minimum=1, maximum=5, value=3, step=1, label=\"Intensity (1=Low, 5=High)\")\n                        mood_log_btn = gr.Button(\"Log Mood & Update Report\", variant=\"secondary\")\n                        mood_output = gr.Markdown(\"### Mood Report\\nLog your mood to see trends.\")\n\n                    # Identity Timeline Column (Aligned)\n                    with gr.Column(scale=2):\n                        gr.Markdown(\"### üìú Identity Timeline Builder\")\n                        timeline_type = gr.Dropdown(\n                            label=\"Entry Type\",\n                            choices=[\"Childhood Interest\", \"Life Event\", \"Skill Acquisition\", \"Career Theme\"],\n                            value=\"Skill Acquisition\"\n                        )\n                        timeline_entry = gr.Textbox(label=\"Timeline Entry Details\", placeholder=\"e.g., 'Taught myself advanced Python on weekends' or 'Moved to a new city' (1-2 sentences)\", lines=3)\n                        \n                        timeline_output = gr.Markdown(\"### Identity Synthesis\\nSynthesized statement and data will appear here.\", elem_id=\"timeline_builder_area\")\n                        \n                mood_log_btn.click(\n                    handle_mood_timeline,\n                    inputs=[mood_selector, mood_intensity, timeline_entry, timeline_type],\n                    outputs=[mood_output, timeline_output]\n                )\n\n            # 5. System Diagnostics (Observability)\n            with gr.TabItem(\"üìä System Diagnostics\"):\n                with gr.Column(scale=1):\n                    gr.Markdown(\"### ‚öôÔ∏è Agent Routing & Performance\")\n                    status_output = gr.Textbox(label=\"Observatory Report\", lines=12, interactive=False, show_label=True, container=True, elem_id=\"status_report_box\")\n                    status_btn = gr.Button(\"üîÑ Refresh Status\", variant=\"secondary\")\n                    context_output = gr.Textbox(label=\"üß† Current Memory Context (Last 50 Interactions)\", lines=12, interactive=False, show_label=True, visible=False, container=True, elem_classes=[\"panel\"])\n                    gr.Markdown(\"\"\"### ü§ñ Active Agent Roles\\nThe Orchestrator automatically routes queries to a specialized role:\n                    - **Resource Curator** (Learning Materials)\n                    - **Q&A Specialist** (General Info/FAQs)\n                    - **Career Advisor** (Guidance/Strategy)\n                    - **Resume Specialist** (CV/Resume Optimization)\n                    - **Interview Coach** (Preparation/Mock Interviews)\n                    - **Career Simulator** (New Feature)\n                    - **Parallel Career Generator** (New Feature)\"\"\", elem_classes=[\"agent-info\"])\n\n        # --- Event handlers ---\n        msg.submit(chat_response, inputs=[msg, chatbot, agent_selector], outputs=[chatbot]).then(lambda: \"\", None, msg).then(get_status, outputs=[status_output])\n        submit.click(chat_response, inputs=[msg, chatbot, agent_selector], outputs=[chatbot]).then(lambda: \"\", None, msg).then(get_status, outputs=[status_output])\n        clear.click(clear_chat, outputs=[chatbot, status_output, context_output])\n        status_btn.click(get_status, outputs=[status_output])\n        view_context_btn.click(get_context, outputs=[context_output]).then(lambda v: gr.update(visible=not v), context_output, context_output)\n        demo.load(get_status, outputs=[status_output])\n    \n    return demo\n\n# --- Main function and execution ---\n\ndef main():\n    print(\"\\n\" + \"=\"*70)\n    print(\"üöÄCareerMatrix AI (Multi-Agent System)\")\n    print(\"=\"*70)\n\n    api_key = Config.GEMINI_API_KEY\n\n    if not api_key:\n        print(\"\\n‚ö†Ô∏è GEMINI_API_KEY not found!\")\n        print(\"\\nüìù Get your free API key at: https://makersuite.google.com/app/apikey\")\n        api_key = input(\"üîë Enter your Gemini API key (or press Enter to exit): \").strip()\n\n        if not api_key:\n            print(\"\\n‚ùå No API key provided. Exiting...\")\n            return\n\n    print(\"\\n‚úÖ API Key configured\")\n    print(\"üîß Initializing Multi-Agent System...\")\n    print(\" - Agents: Curator, Q&A, Advisor, Resume, Interview, Sandbox, Parallel\")\n    print(\" - System Components: Orchestrator, Memory (Sessions & Context), Observatory (Logging/Metrics)\")\n    print(\"\\nüåê Starting web interface...\")\n    print(\"=\"*70 + \"\\n\")\n\n    try:\n        gr.close_all()\n        print(\"üîÑ Closed previous instances\")\n    except:\n        pass\n\n    demo = create_interface(api_key)\n\n    # Function to find an available port\n    def find_free_port(start_port=7860, max_attempts=100):\n        for port in range(start_port, start_port + max_attempts):\n            try:\n                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                sock.bind(('', port))\n                sock.close()\n                return port\n            except OSError:\n                continue\n        return None\n\n    port = find_free_port()\n    if port is None:\n        print(\"‚ö†Ô∏è Could not find available port. Using default...\")\n        port = 7860\n\n    print(f\"üîå Using port: {port}\")\n\n    demo.launch(\n        share=True,\n        server_name=\"0.0.0.0\",\n        server_port=port,\n        show_error=True,\n        quiet=False,\n        prevent_thread_lock=False,\n        inbrowser=False\n    )\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T10:28:42.346137Z","iopub.execute_input":"2025-11-28T10:28:42.346437Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nüöÄCareerMatrix AI (Multi-Agent System)\n======================================================================\n\n‚ö†Ô∏è GEMINI_API_KEY not found!\n\nüìù Get your free API key at: https://makersuite.google.com/app/apikey\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"## üéâ Acknowledgments\n\nWe extend our sincere thanks to:\n\n* Google: For providing the powerful Gemini 2.5 Flash model that made this complex multi-agent architecture feasible and performant.\n\n* Hugging Face/Gradio: For the excellent interface framework, which allows for rapid prototyping and deployment with rich custom styling.\n\n* Kaggle Community: For providing the robust computing environment and the culture of shared learning and innovative project development.\n\n## **üéä Congratulations on Successfully Running CareerMatrix AI!**\n\n## **What You've Accomplished**\n\nBy running this notebook, you have:\n\n* Successfully deployed a complex Multi-Agent System using a modern LLM.\n\n* Managed conversation state and memory within a dynamic system.\n\n* Launched a professional, interactive web interface using Python and Gradio.\n\n* Explored advanced concepts like Heuristic Routing and Observability.\n\n## **Project Developer**\n\n### Team Lead: Hemasree K \n   #### *Institution    :Licet\n   #### *Location       :Chennai,Tamilnadu\n   #### *Current Status :Fresher\n\n## **Why This Project Matters to the Developer:**\n\nI believe that career success should be based on merit and information, not just access. Building this system was a technical challenge that directly serves this personal mission.\n\n## **Impact Potential**\n\nThe greatest potential impact of CareerMatrix AI lies in its ability to scale expert advice. By replacing a single, generic chat model with a team of specialist agents, it offers a more nuanced, reliable, and personalized experience, leveling the playing field for individuals seeking professional growth globally.\n\n## **Final Thoughts**\n\nWe invite you to experiment with all the features, especially the Career Simulation Sandbox and the Mood Tracker, to fully appreciate the depth of this Multi-Agent System.\n\n## **What's Next?**\n\nFuture developments could include:\n\nIntegrating external tools (e.g., job search APIs) into the Resource Curator agent.\n\nImplementing LLM-based Routing to replace the current heuristic routing.\n\nThank you for exploring CareerMatrix AI. Together, we can make quality educational guidance a right, not a privilege.\n\n\n\n\n\n","metadata":{}}]}